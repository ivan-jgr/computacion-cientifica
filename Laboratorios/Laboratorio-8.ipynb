{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métodos Numéricos para la Resolución de Ecuaciones No Lineales\n",
    "\n",
    "Antes de la llegada de las computadoras digitales se disponía de una serie de métodos para encontrar las raíces de ecuaciones algebraicas y trascendentes. En algunos casos, las raíces se obtenían con métodos directos. Sin embargo existen ecuaciones como ésta que se resuelven directamente y aparecen muchas más en las que no es posible encontrar su solución. Por ejemplo, incluso una función tan simple como $f(x) = e^{–x} – x$ no se puede resolver en forma analítica. En tales casos, la única alternativa es una técnica con solución aproximada.\n",
    "\n",
    "En este laboratorio implementará algunos de los métodos más usados para encontrar raíces de ecuaciones no lineales y utilizará implementaciones optimizadas de la librería `scipy`.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ivan-jgr/computacion-cientifica/blob/main/Laboratorios/Laboratorio-8.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método de la Bisección o de Búsqueda Binaria\n",
    "\n",
    "El método de la bisección es un algoritmo en el que el intervalo se divide siempre a la mitad. Si la función cambia de signo sobre un intervalo, se evalúa el valor de la función en el punto medio. La posición de la raíz se determina situándola en el punto medio del subintervalo, dentro del cual ocurre un cambio de signo. El proceso se repite hasta obtener una mejor aproximación.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/d/d9/Bisection_anime.gif\" />\n",
    "\n",
    "\n",
    "Una de las ventajas del método de la bisección es que en cada iteración se reduce el error a la mitad, por lo que el error después de $n$ iteraciónes es:\n",
    "$$\\varepsilon_n = \\dfrac{b-a}{2^n}$$, \n",
    "\n",
    "por lo que podemos determinar a priori el número de iteraciones necesarias para cualquier valor de $\\varepsilon$ deseado:\n",
    "$$\\boxed{n = \\log_2 \\left( \\frac{b-a}{\\varepsilon} \\right)}$$\n",
    "\n",
    "La evidente falla del método es con las raíces dobles, si $f$ tiene más dos raíces en el intervalo $[a, b]$ la condición del cambio de signo ($f(a)f(b) < 0$) no se cumple.\n",
    "\n",
    "#### <ins> Problema 1: </ins>\n",
    "\n",
    "En este problema usted deberá implementar el método de la bisección en la función `busqueda_binaria`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def busqueda_binaria(f, a, b, max_iter):\n",
    "    \"\"\"\n",
    "    Parámetros:\n",
    "    -----------\n",
    "    f: función a la que se le quiere buscar la raiz\n",
    "    a: límite inferior del intervalo\n",
    "    b: límite superior del intervalo\n",
    "    max_iter: máximo número de interaciones\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora usemos su implementación para aproximar el [golden ratio (número aúreo)](https://es.wikipedia.org/wiki/N%C3%BAmero_%C3%A1ureo):\n",
    "\n",
    "$$\\phi = \\dfrac{1 + \\sqrt{5}}{2}.$$\n",
    "\n",
    "Utilizaremos $f(x) = x^2 - x -1$ y `max_iter = 25` en el intervalo $[1, 2]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "\n",
    "def error_relativo(actual_approx, prev_approx):\n",
    "    # Calcula el error relativo\n",
    "    return abs((actual_approx - prev_approx) / actual_approx)\n",
    "\n",
    "\n",
    "# función\n",
    "f = lambda x: x**2 - x - 1\n",
    "# valores a y b\n",
    "a, b = 1, 2\n",
    "# maximo numero de iteraciones\n",
    "N = 25\n",
    "\n",
    "aprox = busqueda_binaria(f, a, b, N)\n",
    "\n",
    "print(f\"Aproximación de la raiz con {N} iteraciones: {aprox}\")\n",
    "print(f\"f(aproximacion) = {f(aprox)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 12, 5\n",
    "fig, axis = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=False)\n",
    "\n",
    "for ax, b in zip(axis.flatten(), [2, 200, 2000, 20000]):\n",
    "    # Ejecutamos el algoritmo con diferentes valores para max_iter para \n",
    "    # poder evaluar el error absoluto\n",
    "    approx_phi = [busqueda_binaria(f, a, b, i) for i in range(1, N+1)]\n",
    "\n",
    "    # Calculemos el error relativo\n",
    "    error_list = [error_relativo(x, y) for x, y in zip(approx_phi[1:], approx_phi[:-1])]\n",
    "\n",
    "    \n",
    "    ax.set_title(f\"a = {a}, b = {b}\")\n",
    "    ax.plot(error_list)\n",
    "    ax.scatter(range(N-1), error_list, c='r')\n",
    "    ax.set_ylabel(\"Error absoluto\")\n",
    "    ax.grid()\n",
    "\n",
    "plt.xlabel(\"N iteraciones\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note como la longitud del intervalo y la posición de la raíz con respecto a los limites del intervalo afectan el error relativo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scipy` posee una implementación del método de la bisección `bisect` en el paquete `optimize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize\n",
    "\n",
    "optimize.bisect(f, 1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Método de Newton-Raphson\n",
    "\n",
    "Tal vez, de las fórmulas para localizar raíces, la fórmula de Newton-Raphson sea la más ampliamente utilizada. Si el valor inicial para la raíz es $x_i$, entonces se puede trazar una tangente desde el punto $[x_i , f(x_i)]$ de la curva. Por lo común, el punto donde esta tangente cruza al eje x representa una aproximación mejorada de la raíz.\n",
    "\n",
    "El método de Newton-Raphson es un método iterativo en donde la fórmula para el siguiente punto en la aproximación está dado por \n",
    "\n",
    "$$\\boxed{x_{n+1} = x_n - \\dfrac{f(x_n)}{f'(x_n)}}$$\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/356/1*PP_rs7kMUiq-kv1CzHcuzQ.gif\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins> Problema 2: </ins>\n",
    "\n",
    "En este problema usted deberá implementar el método de Newton-Raphson en la función `newton_raphson`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_raphson(f, Df, x0, epsilon, max_iter):\n",
    "    \"\"\"\n",
    "    Parámetros:\n",
    "    -----------\n",
    "    f: función a la que se le quiere buscar la raiz\n",
    "    Df: derivada de f\n",
    "    x0: estimación inicial para la raíz\n",
    "    epsilon: tolerancia, i.e. deternerse si abs(f(x_0)) < epsilon\n",
    "    max_iter: máximo número de interaciones\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora usemos su implementación para aproximar el [super golden ratio](https://en.wikipedia.org/wiki/Supergolden_ratio):\n",
    "\n",
    "$$\\psi = \\frac{1 + \\sqrt[3]{\\frac{29 + 3\\sqrt{93}}{2}} + \\sqrt[3]{\\frac{29 - 3\\sqrt{93}}{2}}}{3}$$\n",
    "\n",
    "Utilizaremos $f(x) = x^3 - x^2 -1$, $x_0 = 10^{-10}$ `max_iter = 10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: x**3 - x**2 - 1\n",
    "Df = lambda x: 3*x**2 - 2*x\n",
    "approx = newton_raphson(f,Df,1,1e-10,10)\n",
    "print(approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 12, 5\n",
    "fig, axis = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=False)\n",
    "\n",
    "for ax, x0 in zip(axis.flatten(), [10, 100, 1000, 20000]):\n",
    "    # Ejecutamos el algoritmo con diferentes valores para max_iter para \n",
    "    # poder evaluar el error absoluto después\n",
    "    approx_phi = [newton_raphson(f, Df, x0, 1e-10, i) for i in range(1, N+1)]\n",
    "\n",
    "    # Calculemos el error relativo\n",
    "    error_list = [error_relativo(x, y) for x, y in zip(approx_phi[1:], approx_phi[:-1])]\n",
    "\n",
    "    \n",
    "    ax.set_title(f\"x0 = {x0}\")\n",
    "    ax.plot(error_list)\n",
    "    ax.scatter(range(N-1), error_list, c='r')\n",
    "    ax.set_ylabel(\"Error absoluto\")\n",
    "    \n",
    "    ax.grid()\n",
    "\n",
    "plt.xlabel(\"N iteraciones\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scipy` posee una implementación del método de Newton-Raphson `newton` en el paquete `optimize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: x**3 - x**2 - 1\n",
    "Df = lambda x: 3*x**2 - 2*x\n",
    "approx = optimize.newton(f, 10, fprime=Df)\n",
    "print(approx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque en general el método de Newton-Raphson es muy eficiente, hay situaciones donde se comporta de manera deficiente. Por ejemplo en el caso especial de raíces múltiples que se analizará más adelante en este capítulo. Sin embargo, también cuando se trata de raíces simples, se encuentran dificultades, como en el siguiente ejemplo.\n",
    "\n",
    "Trataremos de encontrar al raíz positiva de $f(x) = x^{10} - 1$ con $x_0 = 0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: x**10 - 1\n",
    "Df = lambda x: 10*x**9\n",
    "x0 = 0.5\n",
    "approx, info = optimize.newton(f, x0, fprime=Df, full_output=True)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que, a pesar que le método si converge, lo hace de una forma muy lenta (incluso cuando $x_0$ está muy cerca de la raíz). Tomó 43 iteraciones encontrar la aproximación.\n",
    "\n",
    "El método de Newton-Raphson incluso diverge en algunos casos, por ejemplo con $f(x) = x^{\\frac{1}{3}}$, donde la recta tangente es casi vertical cerca de $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: x**(1/3)\n",
    "Df = lambda x: (1/3)*x**(-2/3)\n",
    "x0 = 0.1\n",
    "# Usemos hasta 1000 iteraciones, el numero de iteraciones por defecto es 50.\n",
    "approx, info = optimize.newton(f, x0, fprime=Df, full_output=True, maxiter=1000)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Método de la Secante\n",
    "\n",
    "\n",
    "Un problema potencial en la implementación del método de Newton-Raphson es la evaluación de la derivada. Aunque esto no es un inconveniente para los polinomios ni para muchas otras funciones, existen algunas funciones cuyas derivadas en ocasiones resultan muy difíciles de calcular. En dichos casos, la derivada se puede aproximar\n",
    "mediante una diferencia finita dividida hacia atrás:\n",
    "\n",
    "$$f'(x_n) \\approx \\dfrac{f(x_{n-1}) - f(x_n)}{x_{n-1} - x_n}$$\n",
    "\n",
    "Si sustituimos esta aproximación en la ecuación de Newton-Raphson obtenemos:\n",
    "\n",
    "$$\\boxed{x_{n+1} = x_n - f(x_n) \\dfrac{x_{n-1} -x_n}{f(x_{n-1})  - f(x_n)}}$$\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/b/be/Metodo_delle_secanti.gif\" width=\"40%\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### <ins> Problema 3: </ins>\n",
    "\n",
    "En este problema usted deberá implementar el método de la secante en la función `secante`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def secante(f, x0, x1, epsilon, max_iter):\n",
    "    \"\"\"\n",
    "    Parámetros:\n",
    "    -----------\n",
    "    f: función a la que se le quiere buscar la raiz\n",
    "    x0, x1: valores iniciales para el método.\n",
    "    epsilon: tolerancia, i.e. deternerse si abs(f(x_0)) < epsilon\n",
    "    max_iter: máximo número de interaciones\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuevamente, usemos su implementación para buscar el [super golden ratio](https://en.wikipedia.org/wiki/Supergolden_ratio):\n",
    "\n",
    "Utilizaremos $f(x) = x^3 - x^2 -1$, $x_0 = 1$, $x_1 = 2$ y `max_iter = 10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: x**3 - x**2 - 1\n",
    "Df = lambda x: 3*x**2 - 2*x\n",
    "approx = secante(f, 1, 2, 1e-10,10)\n",
    "print(approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 12, 5\n",
    "fig, axis = plt.subplots(nrows=2, ncols=2, sharex=True, sharey=False)\n",
    "\n",
    "for ax, (x0, x1) in zip(axis.flatten(), [(0, 10), (0, 100), (-100, 1000), (-1000, 20000)]):\n",
    "    # Ejecutamos el algoritmo con diferentes valores para max_iter para \n",
    "    # poder evaluar el error absoluto después\n",
    "    approx_phi = [secante(f, x0, x1, 1e-10, i) for i in range(1, N+1)]\n",
    "\n",
    "    # Calculemos el error relativo\n",
    "    error_list = [error_relativo(x, y) for x, y in zip(approx_phi[1:], approx_phi[:-1])]\n",
    "\n",
    "    \n",
    "    ax.set_title(f\"x0 = {x0}, x1 = {x1}\")\n",
    "    ax.plot(error_list)\n",
    "    ax.scatter(range(N-1), error_list, c='r')\n",
    "    ax.set_ylabel(\"Error absoluto\")\n",
    "    \n",
    "    ax.grid()\n",
    "\n",
    "plt.xlabel(\"N iteraciones\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scipy` posee una implementación del método de la secante `newton` en el paquete `optimize`. Si no se le pasa el argumento `fprime`, por defecto se usa el método de la secante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: x**3 - x**2 - 1\n",
    "Df = lambda x: 3*x**2 - 2*x\n",
    "x0, x1 = 1, 2\n",
    "approx, info = optimize.newton(f, x0, x1=x1, full_output=True)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puede encontrar la lista completa de métodos numéricos para resolver ecuaciones no lineales implementados en `scipy`en la documentación: https://docs.scipy.org/doc/scipy/reference/optimize.html#root-finding. Para el siguiente proble utilice estas implementaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <ins> Problema 4: </ins>\n",
    "\n",
    "a) Utilíce el método del punto fijo (doc: https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fixed_point.html#scipy.optimize.fixed_point) para localizar la raíz de $$f(x) = 2 \\sin \\left( \\sqrt{x}\\right) - x .$$\n",
    "\n",
    "Haga una elección inicial de $x_0 = 0.5$ y genere una gráfica de $f(x)$, incluya la estimacion inicial y el punto fijo encontrado.\n",
    "Recuerde que el método le devuelve un valor `x0` tal que `f(x0) == x0` y no una raíz de `f(x)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resuelva aquí el problema 4a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Localice la primera raíz positiva de \n",
    "$$f(x) = \\sin x + \\cos (1 + x^2) - 1,$$\n",
    "\n",
    "donde $x$ está en radianes. utilíce el método de la secante con valores iniciales de:\n",
    "\n",
    "- $x_0 = 1.0, x_1 = 3.0$.\n",
    "- $x_0 = 1.5, x_1 = 2.5$\n",
    "- $x_0 = 1.5, x_1 = 2.25$\n",
    "\n",
    "En cada caso haga `full_output=True` y vea la cantidad de iteraciones que se realizaron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resuelva aquí el problema 4b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resuelva aquí el problema 4b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resuelva aquí el problema 4b3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Aproxime la raiz cuadrada positiva de $18$ usando el método de la bisección. Emplee los valores iniciales adecuados y aproxime la raíz con una tolerancia del $0.5 \\%$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resuelva aquí el problema 4c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "# **Instrucciones Generales**\n",
    "1. Este laboratorio será realizado de manera *individual*.\n",
    "2. **Fecha de entrega**: Lunes 25 de Octubre de 2021. Su solución debe subirla en un archivo ZIP enviado por GES y debe contener el archivo .ipynb con sus respuesta a cada inciso solicitado en cada uno de los *Problemas* indicados en la parte superior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "math",
   "language": "python",
   "name": "math"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
